{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing the 10,000 Song Subset\n",
    "\n",
    "*Andrea Soto*  \n",
    "*MIDS W205 Final Project*  \n",
    "*Project Name: Graph Model of the Million Song Dataset*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook processess the Million Song Dataset Subset which contains a sample of 10,000 songs from the main dataset. **The goal is to get familiarized with the data, and to develop and test the code on the smaller dataset.** The code developed was then compiled in scripts that were used to process the full dataset.\n",
    "\n",
    "This notebook assumes that the instance has been configured according to the notebook [Step 1 - Configuration.ipynb](./Step 1 - Step 1 - Configuration.ipynb).\n",
    "\n",
    "Two sources of data were used:\n",
    "\n",
    "1. **Million Song Dataset (MSD):** contains track, song, artist, and album metadata. It also contains artist similarity and artist tags. This was the main datasource for this project. The data is stored in HDF5 format, with one file per song.\n",
    "A detail description of the MSD project can be found [here](http://labrosa.ee.columbia.edu/millionsong/) and the filed list can be found [here](http://labrosa.ee.columbia.edu/millionsong/faq).\n",
    "2. **Last.fm Dataset:** contains information about song similarity and song tags. This information was used to complement the MSD. This data is stored in JSON format, with one file per song. A detail desctiption of the Last.fm data can be found [here](http://labrosa.ee.columbia.edu/millionsong/lastfm).\n",
    "\n",
    "For reference, a small sample of the tree structue of each dataset is shown below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MillionSongSubset/data/\n",
    "|-- A\n",
    "|   |-- A\n",
    "|   |   |-- A\n",
    "|   |   |   |-- TRAAAAW128F429D538.h5\n",
    "|   |   |   |-- TRAAABD128F429CF47.h5\n",
    "|   |   |   |-- TRAAADZ128F9348C2E.h5\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- B\n",
    "|   |   |   |-- TRAABCL128F4286650.h5\n",
    "|   |   |   |-- TRAABDL12903CAABBA.h5\n",
    "|   |   |   |-- TRAABJL12903CDCF1A.h5\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- C\n",
    "|   |   |   |-- TRAACCG128F92E8A55.h5\n",
    "|   |   |   |-- TRAACER128F4290F96.h5\n",
    "|   |   |   |-- TRAACFV128F935E50B.h5\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- D\n",
    "|   |   |-- ...\n",
    "|   |   |-- X\n",
    "|   |   |-- Y\n",
    "|   |   `-- Z\n",
    "|   |-- B\n",
    "|   |   |-- A\n",
    "|   |   |-- ...\n",
    "|   |   `-- Z\n",
    "|   |-- C\n",
    "|   |-- ...\n",
    "|   `-- Z\n",
    "`-- B\n",
    "    |-- A\n",
    "    |   |-- A\n",
    "    |   |-- B\n",
    "    |   |-- ...\n",
    "    |   `-- Z\n",
    "    |-- B\n",
    "    |-- ...\n",
    "    `-- Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MillionSongSubset/lastfm_subset/\n",
    "|-- A\n",
    "|   |-- A\n",
    "|   |   |-- A\n",
    "|   |   |   |-- TRAAAAW128F429D538.json\n",
    "|   |   |   |-- TRAAABD128F429CF47.json\n",
    "|   |   |   |-- TRAAADZ128F9348C2E.json\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- B\n",
    "|   |   |   |-- TRAABDL12903CAABBA.json\n",
    "|   |   |   |-- TRAABJL12903CDCF1A.json\n",
    "|   |   |   |-- TRAABJV128F1460C49.json\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- C\n",
    "|   |   |   |-- TRAACCG128F92E8A55.json\n",
    "|   |   |   |-- TRAACER128F4290F96.json\n",
    "|   |   |   |-- TRAACFV128F935E50B.json\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- D\n",
    "|   |   |-- ...\n",
    "|   |   |-- X\n",
    "|   |   |-- Y\n",
    "|   |   `-- Z\n",
    "|   |-- B\n",
    "|   |   |-- A\n",
    "|   |   |-- ...\n",
    "|   |   `-- Z\n",
    "|   |-- C\n",
    "|   |-- ...\n",
    "|   `-- Z\n",
    "`-- B\n",
    "    |-- A\n",
    "    |   |-- A\n",
    "    |   |-- B\n",
    "    |   |-- ...\n",
    "    |   `-- Z\n",
    "    |-- B\n",
    "    |-- ...\n",
    "    `-- Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Workflow\n",
    "\n",
    "The data was transformed into CSV files containing the nodes and realtionship structure for Neo4j. This CSV files where created to leaverage the `LOAD CVS` functionality of Neo4j, which makes loading large graphs into Neo4j faster and scalable. \n",
    "\n",
    "The Million Song Dataset stores each song in HDF5 format and the Last.fm dataset stores each song in JSON format. \n",
    "\n",
    "The steps followed in this notebook were:\n",
    "\n",
    "1. Create a list of the song files with the full path to each file\n",
    "2. In Spark, read each file in the list and extract the information\n",
    "3. In Spark, transform the extracted data to create CSV files for each node and relationsip type. Separate transformations were requiered for each node and relationship type\n",
    "4. Save the transformed data using Spark's `saveAsTextFile()` operation\n",
    "5. Since the `saveAsTextFile()` operation generates several files named 'part-000xx', the data was merged into a single .csv file and headers were added to ease readability. This was done with bash commands\n",
    "\n",
    "# Matching Errors\n",
    "\n",
    "The MSD team found some matching errors between tracks and songs in the data. They created a list of (song id, tack id) pairs that are not trusted and they suggest removing this pairs from the data. These missmatches were removed from the data as part of the transformation process.\n",
    "\n",
    "For more details see:\n",
    "- http://labrosa.ee.columbia.edu/millionsong/blog/12-1-2-matching-errors-taste-profile-and-msd\n",
    "- http://labrosa.ee.columbia.edu/millionsong/blog/12-2-12-fixing-matching-errors\n",
    "\n",
    "### The following tree shows the final directory structure after processing the Subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/asoto/projectW205/MillionSongSubset/\r\n",
      "|-- AdditionalFiles\r\n",
      "|   |-- LICENSE\r\n",
      "|   |-- README\r\n",
      "|   |-- subset_artist_location.txt\r\n",
      "|   |-- subset_artist_similarity.db\r\n",
      "|   |-- subset_artist_term.db\r\n",
      "|   |-- subset_msd_summary_file.h5\r\n",
      "|   |-- subset_track_metadata.db\r\n",
      "|   |-- subset_tracks_per_year.txt\r\n",
      "|   |-- subset_unique_artists.txt\r\n",
      "|   |-- subset_unique_mbtags.txt\r\n",
      "|   |-- subset_unique_terms.txt\r\n",
      "|   `-- subset_unique_tracks.txt\r\n",
      "|-- data\r\n",
      "|   |-- A\r\n",
      "|   `-- B\r\n",
      "|-- graph\r\n",
      "|   |-- nodes_albums.csv\r\n",
      "|   |-- nodes_artists.csv\r\n",
      "|   |-- nodes_songs.csv\r\n",
      "|   |-- nodes_tags.csv\r\n",
      "|   |-- nodes_years.csv\r\n",
      "|   |-- rel_artist_has_album.csv\r\n",
      "|   |-- rel_artist_has_tag.csv\r\n",
      "|   |-- rel_performs.csv\r\n",
      "|   |-- rel_similar_artists.csv\r\n",
      "|   |-- rel_similar_songs.csv\r\n",
      "|   |-- rel_song_has_tag.csv\r\n",
      "|   |-- rel_song_in_album.csv\r\n",
      "|   `-- rel_song_year.csv\r\n",
      "|-- lastfm_subset\r\n",
      "|   |-- A\r\n",
      "|   `-- B\r\n",
      "|-- list_hdf5_files.txt\r\n",
      "|-- list_lastfm_files.txt\r\n",
      "`-- tmp\r\n",
      "    |-- nodes_albums\r\n",
      "    |-- nodes_artists\r\n",
      "    |-- nodes_songs\r\n",
      "    |-- nodes_tags\r\n",
      "    |-- nodes_years\r\n",
      "    |-- rel_artist_has_album\r\n",
      "    |-- rel_artist_has_tag\r\n",
      "    |-- rel_performs\r\n",
      "    |-- rel_similar_artists\r\n",
      "    |-- rel_similar_songs\r\n",
      "    |-- rel_song_has_tag\r\n",
      "    |-- rel_song_in_album\r\n",
      "    `-- rel_song_year\r\n",
      "\r\n",
      "22 directories, 27 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -L 2 /data/asoto/projectW205/MillionSongSubset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The directories **'AdditionalFiles'**, **'data'**  and **'lastfm_subset'** are input folders downloaded from the MSD website\n",
    "- The directories **'graph'** and **'tmp'** will be created as part of the extract and transfor process. The intermediate output from spark will be saved in **'tmp'** and the results will be consolidated into CSV files with headers in the **'graph'** folder.\n",
    "- The files **'list_hdf5_files.txt'** and **'list_lastfm_files.txt'** are the list of paths to the song files that will be used to read within Spark. These are the first output created in the dataflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Subset Data - 10,000 songs\n",
    "\n",
    "The **'download_subsetdata.sh'** script downloads the MSD and Last.fm datasets into the current directory. The Last.fm is downloaded inside the MillionSongSubset folder.\n",
    "\n",
    "The final directory structure is:\n",
    "\n",
    "(current directory)  \n",
    "| -- MillionSongSubset  \n",
    "| --  -- | -- Additional files  \n",
    "| --  -- | -- data  \n",
    "| --  -- | -- lastfm_subset   \n",
    "\n",
    "All the outputs of processing the Subset dataset will be stored under the main directoyr 'MillionSongSubset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/download_subsetdata.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/download_subsetdata.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# Download data subset of 10,000 songs, ~1GB to develop and test code\n",
    "wget http://static.echonest.com/millionsongsubset_full.tar.gz\n",
    "wait\n",
    "tar xvzf millionsongsubset_full.tar.gz\n",
    "wait\n",
    "rm millionsongsubset_full.tar.gz\n",
    "\n",
    "cd MillionSongSubset\n",
    "\n",
    "# Download last-fm data with song similarities\n",
    "wget http://labrosa.ee.columbia.edu/millionsong/sites/default/files/lastfm/lastfm_subset.zip\n",
    "unzip lastfm_subset.zip\n",
    "rm lastfm_subset.zip\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download untrusted Songs to be filtered out\n",
    "\n",
    "Download a copy to process with the subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2015-12-14 07:56:28--  http://labrosa.ee.columbia.edu/millionsong/sites/default/files/tasteprofile/sid_mismatches.txt\n",
      "Resolving labrosa.ee.columbia.edu... 128.59.66.11\n",
      "Connecting to labrosa.ee.columbia.edu|128.59.66.11|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2026182 (1.9M) [text/plain]\n",
      "Saving to: `sid_mismatches.txt'\n",
      "\n",
      "100%[======================================>] 2,026,182   7.93M/s   in 0.2s    \n",
      "\n",
      "2015-12-14 07:56:28 (7.93 MB/s) - `sid_mismatches.txt' saved [2026182/2026182]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://labrosa.ee.columbia.edu/millionsong/sites/default/files/tasteprofile/sid_mismatches.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Spark Context in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.5.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Sep 15 2015 14:50:01)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#Escape L for line numbers\n",
    "spark_home = os.environ['SPARK_HOME'] = '/data/spark15'\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f1690c88910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check spark context exists\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of HDF5 files and JSON files for the Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run from 'msd_project' directory\n",
    "# List the files with their full path and store the list in a .txt file\n",
    "# This list of files will then be read in Spark to parse the actual files\n",
    "\n",
    "# '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''' \n",
    "# Million Song Dataset\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Path to list of song files - Million Song Subset - \n",
    "song_paths = 'MillionSongSubset/list_hdf5_files.txt'\n",
    "\n",
    "# If file does not exits, create it\n",
    "if not os.path.exists(song_paths):\n",
    "\n",
    "    # List all paths of songs and save them to \n",
    "    get_song_paths = glob.glob('./MillionSongSubset/data/*/*/*/*.h5')\n",
    "    \n",
    "    with open(song_paths,'w') as f:\n",
    "        f.writelines('\\n'.join(p for p in get_song_paths))\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "# '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''' \n",
    "# Last.fm Dataset\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Path to list of song files - LastFM Song Similarity and Tags -\n",
    "lastfm_paths = 'MillionSongSubset/list_lastfm_files.txt'\n",
    "\n",
    "# If file does not exits, create it\n",
    "if not os.path.exists(lastfm_paths):\n",
    "\n",
    "    # List all paths of songs and save them to \n",
    "    get_song_paths = glob.glob('./MillionSongSubset/lastfm_subset/*/*/*/*.json')\n",
    "    \n",
    "    with open(lastfm_paths,'w') as f:\n",
    "        f.writelines('\\n'.join(p for p in get_song_paths))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read list of files to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdir = os.getcwd()\n",
    "\n",
    "# Create RDD with the list of HDF5 song files\n",
    "path = os.path.join(cdir, song_paths)\n",
    "song_pathsRDD = sc.textFile('file://'+path)\n",
    "\n",
    "# Create RDD with the list of JSON song files\n",
    "path = os.path.join(cdir, lastfm_paths)\n",
    "lastfm_pathsRDD = sc.textFile('file://'+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample list of MSD song files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'./MillionSongSubset/data/B/B/O/TRBBOPX12903D106F7.h5',\n",
       " u'./MillionSongSubset/data/B/B/O/TRBBOKQ128F933AE7C.h5',\n",
       " u'./MillionSongSubset/data/B/B/O/TRBBOPV12903CFB50F.h5',\n",
       " u'./MillionSongSubset/data/B/B/O/TRBBOJM12903CD1BDD.h5',\n",
       " u'./MillionSongSubset/data/B/B/O/TRBBOBQ12903CC5186.h5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_pathsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample list of Last.fm song files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'./MillionSongSubset/lastfm_subset/B/B/O/TRBBOBO128F425FDFC.json',\n",
       " u'./MillionSongSubset/lastfm_subset/B/B/O/TRBBOPX12903D106F7.json',\n",
       " u'./MillionSongSubset/lastfm_subset/B/B/O/TRBBOBQ12903CC5186.json',\n",
       " u'./MillionSongSubset/lastfm_subset/B/B/O/TRBBOME12903CC3862.json',\n",
       " u'./MillionSongSubset/lastfm_subset/B/B/O/TRBBOFH128F14A2A46.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfm_pathsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the (song id, track id) pair mismatches\n",
    "\n",
    "The raw mismatched file has the following general structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ERROR: <'songID', 'trackID'> 'descrption showing mismatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example lines from the file are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ERROR: <SOVWUNG12A8C137891 TRMGMLW128F426A200> Warlock  -  Copy of a Copy  !=  Sickboy  -  She's out of way  \n",
    "ERROR: <SOJTFZA12A8C13704E TRMGGOK128F426FDEB> Bike  -  Circus Kids  !=  Slut  -  Gloom  \n",
    "ERROR: <SOZZXCP12A8C13832E TRMGQMW128F9311251> Musiq  -  Solong  !=  Suthun Boy  -  Full Blown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_mismatches(line):\n",
    "    '''\n",
    "    This function extracts the songID and trackID of the mismatched records.\n",
    "    Returned value: ('songID', 'trackID')\n",
    "    '''\n",
    "    return line[8:45].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD with the song-track pairs that need to be removed\n",
    "toRemoveRDD = sc.textFile('file://'+cdir+'/sid_mismatches.txt').map(parse_mismatches)\n",
    "songsToRemove = sc.broadcast(toRemoveRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of (song,track) pairs to remove**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toRemoveRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract MSD song information\n",
    "\n",
    "The MSD song data was extracted into an RDD were each song is represendted with a python dictionary having the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{   'a_similar': array(['artistId', 'artistId', ... , 'artistId']),  \n",
    "      'a_terms': array(['term1', 'term2', ..., 'termN']),  \n",
    "       'a_tfrq': array([ ]),  \n",
    "         'a_tw': array([ ]),  \n",
    "        'album': 'album name',  \n",
    "  'artist_7did': '7digit artist id',  \n",
    "    'artist_id': 'Echo Nest artist id',  \n",
    "  'artist_mbid': 'Music Brain artist id',  \n",
    "  'artist_name': 'Artist name',  \n",
    "        'dance': 0.0,  \n",
    "          'dur': 125.7,  \n",
    "       'energy': 0.0,  \n",
    "     'loudness': -9.3,  \n",
    "      'song_id': 'Echo Nest song id',  \n",
    "        'title': 'Song title',  \n",
    "     'track_id': 'Echo Nest trach id',  \n",
    "         'year': 1990  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to read MSD HDF5 files and extract data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_h5_info(path):\n",
    "    '''\n",
    "    Takes a path to a song stored as an HDF5 file and returns a dictionary with the \n",
    "    information that will be included in the graph\n",
    "    ''' \n",
    "    d = {}\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        song_id = f['metadata']['songs']['song_id'][0]\n",
    "        track_id = f['analysis']['songs']['track_id'][0]\n",
    "        \n",
    "        if (song_id, track_id) not in songsToRemove.value:\n",
    "\n",
    "            # --- Artist Info -----------------------------\n",
    "            d.setdefault('artist_id', f['metadata']['songs']['artist_id'][0])\n",
    "            d.setdefault('artist_mbid', f['metadata']['songs']['artist_mbid'][0])\n",
    "            d.setdefault('artist_7did', f['metadata']['songs']['artist_7digitalid'][0])\n",
    "            d.setdefault('artist_name', f['metadata']['songs']['artist_name'][0])\n",
    "\n",
    "            # --- Song Info -----------------------------\n",
    "            d.setdefault('song_id', song_id)\n",
    "            d.setdefault('track_id', track_id)\n",
    "            d.setdefault('title', f['metadata']['songs']['title'][0])\n",
    "            d.setdefault('dance', f['analysis']['songs']['danceability'][0])\n",
    "            d.setdefault('dur', f['analysis']['songs']['duration'][0])\n",
    "            d.setdefault('energy', f['analysis']['songs']['energy'][0])\n",
    "            d.setdefault('loudness', f['analysis']['songs']['loudness'][0])\n",
    "\n",
    "            # --- Year -----------------------------\n",
    "            d.setdefault('year', f['musicbrainz']['songs']['year'][0])\n",
    "\n",
    "            # --- Album -----------------------------\n",
    "            d.setdefault('album', f['metadata']['songs']['release'][0])\n",
    "\n",
    "            # --- Similar Artist -----------------------------\n",
    "            d.setdefault('a_similar', np.array(f['metadata']['similar_artists']))\n",
    "\n",
    "            # --- Artist Terms -----------------------------\n",
    "            d.setdefault('a_terms', np.array(f['metadata']['artist_terms']))\n",
    "            d.setdefault('a_tfrq', np.array(f['metadata']['artist_terms_freq']))\n",
    "            d.setdefault('a_tw', np.array(f['metadata']['artist_terms_weight']))\n",
    "\n",
    "            return d\n",
    "        else: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract MSD song data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract song information\n",
    "songsRDD = song_pathsRDD.map(get_h5_info).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample song extracted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a_similar': array(['ARRGFFD1187B9AF330', 'ARIVAXF122BCFCACF3', 'AR6LT5K1187FB562A9',\n",
       "         'ARI8PQM1187B99577F', 'ARHYS6D1187FB5BBA4', 'AR1XPEO1187B9B560E',\n",
       "         'AREUFRU1187FB49BEF', 'AR41E9U1187FB5573B', 'AR6AD5N1187FB52F22',\n",
       "         'ARCF9FU119B866967B', 'ARBVIM21187FB520A2', 'ARISRD71187FB57AE8',\n",
       "         'ARAMB6Q1187B99DE68', 'ARE3JFT1187FB589B6', 'ARJMAW61187B9A6148',\n",
       "         'ARP6QCL1187FB36142', 'ARJ41O41187B9A0F53', 'AR1P7OW1187FB5B3E1',\n",
       "         'ARVMRVW1187FB392FF', 'ARA8DDQ1187B9AE3A0', 'AR3QE2N1187FB588CA',\n",
       "         'AROF8OV1187FB55B85', 'AR9JJ761187B9AF496', 'ARWCIR91187FB55D30',\n",
       "         'ARXWXEB1187B9A8592', 'AR0WGKH11C8A414A0F', 'ARJ8S571187FB4550A',\n",
       "         'ARWY36G11A348EFDFC', 'AR5SZEA1187B9BA0AA', 'ARPFC0M1187B9B969D',\n",
       "         'ARAEZVZ1187FB573A8', 'AR52O1K1187FB4C98D', 'ARDEOJT1187B990229',\n",
       "         'ARKWACN11A348F0476', 'ARL26PR1187FB576E5', 'ARE3RNX1187B9ADD8B',\n",
       "         'AROLJZM1187B994C58', 'ARXOPQ911C8A41568B', 'ARAFF5A1187FB56142',\n",
       "         'ARJWW0V1187B9B6886', 'ARCYK3E1187FB542DC', 'ARBO7VC1187FB4222C',\n",
       "         'ARK0SQJ1187B9942CF', 'ARV5WFJ1187B989B3C', 'ARGZ6ZJ1187B997EE1',\n",
       "         'AR5UA0T1187B9A6773', 'ARSBQOU1187FB4DABF', 'ARPAMQ61187B98CE49',\n",
       "         'ARAFQRJ1187FB49CFB', 'ARZXQIQ1241B9C467B', 'ARZBDBS11F4C847F7E',\n",
       "         'AROCMBL11E2835D601', 'ARBRL2P1187B9AF9E4', 'AR44JUQ1187B98FD6D',\n",
       "         'AR67UCD1187B9B1585', 'ARR2TI31187FB380FE', 'AR3J0BE119B866925A',\n",
       "         'AR2UOIC1187FB3CFB8', 'ARS0W831187B9AF0B7', 'AR5MOHS1187B9B5F41',\n",
       "         'ARHUCDJ1187B9A3697', 'ARW27YL1187B9B6AE2', 'ARL69431187FB4CD2F',\n",
       "         'ARVWLC11187FB56F36', 'ARJ3Z7E1187B994711', 'AR5OYUJ1187FB38DE9',\n",
       "         'ARSZUJB1187FB440C0', 'AROQCSJ11F4C847A75', 'ARFQEQQ124BAE72E24',\n",
       "         'ARNJ7441187B999AFD', 'ARTOFZO1187B9AF7FA', 'ARF4PL81187B989B34',\n",
       "         'ARS7W7E1187B9A9D03', 'ARB7V4S1187B99E979', 'ARN2JDN1187FB54F7D',\n",
       "         'ARNPOGM1187FB53970', 'AR6NRQI1187FB37544', 'ARNJXVD1187FB4B37D',\n",
       "         'ARIGLET11F91D36076', 'ARGWIHH1187B9A79B0', 'ARQUDHR1269FCD5EC4',\n",
       "         'ARWKIZS12298900133', 'ARW5IRV1187B99C28A', 'ARSNAAQ122BCFCB0DC',\n",
       "         'ARSFHIQ1187B9B6AE0', 'ARK24KH1187B9B6B93', 'AR1F3IJ1187B9980B4',\n",
       "         'ARIVKUW1241B9C8BC1', 'ARZJ8DO1187FB41CD5', 'ARVEVG51187B9B4E8A',\n",
       "         'ARIGGCC11C8A415404', 'ARZLSHC1187B99CDC4', 'AR21JVF1187B994846',\n",
       "         'ARRZTHE1274363C3F3', 'ARWIEIE11F4C83F267', 'ARR1QOR1187FB5B2AF',\n",
       "         'AR8UFNT1187B9A3801', 'ARTEGNK1187FB554BC', 'ARAZ9QJ1187B98C413',\n",
       "         'ARCYJTW11F4C840F74'], \n",
       "        dtype='|S20'),\n",
       "  'a_terms': array(['twee pop', 'cantonese pop', 'chill-out', 'indie pop', 'dream pop',\n",
       "         'post rock', 'rock', 'pop', 'intelligent dance music', 'emo',\n",
       "         'female vocalist', 'alternative rock', 'indie rock', 'electronica',\n",
       "         'twee', 'indie', 'chinese', 'electronic', '60s rock', 'hong kong',\n",
       "         'ambient', 'japanese', 'lo-fi', 'female', 'mellow', 'noise',\n",
       "         'relax', 'synth', 'dreamy', '60s pop', 'synthpop', 'cantonese',\n",
       "         'taiwan', 'cpop', 'warm', 'china', 'indietronica'], \n",
       "        dtype='|S256'),\n",
       "  'a_tfrq': array([ 1.        ,  0.80939183,  0.80939183,  0.93880319,  0.80976085,\n",
       "          0.80939183,  1.        ,  0.92149978,  0.66476824,  0.80939183,\n",
       "          0.75274097,  0.80939183,  0.80939183,  0.80939183,  0.61995369,\n",
       "          0.81792323,  0.55390212,  0.80031268,  0.50639092,  0.49098705,\n",
       "          0.68874867,  0.64302675,  0.57113689,  0.61033823,  0.57695483,\n",
       "          0.61318464,  0.52027211,  0.51814527,  0.49359934,  0.4377939 ,\n",
       "          0.53447201,  0.40327279,  0.39850275,  0.38231346,  0.38010229,\n",
       "          0.36834221,  0.3808469 ]),\n",
       "  'a_tw': array([ 1.        ,  0.85696653,  0.85696653,  0.83246706,  0.82722359,\n",
       "          0.79848128,  0.78009774,  0.75040577,  0.74844015,  0.74058383,\n",
       "          0.71473443,  0.71099087,  0.70245568,  0.68665812,  0.682504  ,\n",
       "          0.6669152 ,  0.66524557,  0.64493967,  0.62959289,  0.61803374,\n",
       "          0.60737211,  0.60737148,  0.60737135,  0.60736906,  0.60736848,\n",
       "          0.60736455,  0.60734521,  0.60734473,  0.60733918,  0.5781173 ,\n",
       "          0.57215479,  0.55221246,  0.54863299,  0.53648446,  0.53482518,\n",
       "          0.52600035,  0.51734149]),\n",
       "  'album': 'Zoo Is Sad_ People Are Cruel',\n",
       "  'artist_7did': 219434,\n",
       "  'artist_id': 'ARAO0RA1187FB587F2',\n",
       "  'artist_mbid': 'ea6185ea-0138-4b8c-a81a-e8fb90d7c680',\n",
       "  'artist_name': 'My Little Airport',\n",
       "  'dance': 0.0,\n",
       "  'dur': 125.70077000000001,\n",
       "  'energy': 0.0,\n",
       "  'loudness': -9.3610000000000007,\n",
       "  'song_id': 'SOFFUHF12AC4689476',\n",
       "  'title': 'Leo_ Are You Still Jumping Out Of Windows In Expensive Clothes?',\n",
       "  'track_id': 'TRBBOPX12903D106F7',\n",
       "  'year': 0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Last.fm song information\n",
    "\n",
    "The Last.fm data has the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{    'artist': u'DeGarmo & Key',\n",
    "   'similars': [['song id', similarity measure], ['song id', similarity measure]],\n",
    "       'tags': [['tag one', weight],['some tag', weight]],\n",
    "  'timestamp': '2011-09-08 01:41:45.776631',\n",
    "      'title': 'Jericho  (Straight On Album Version)',\n",
    "   'track_id': 'TRBBOBO128F425FDFC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to read Last.fm JSON files and extract data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_json_info(path):\n",
    "    with open(path) as data_file:    \n",
    "        return json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract song information\n",
    "lastfmRDD = lastfm_pathsRDD.map(get_json_info).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'artist': u'DeGarmo & Key',\n",
       "  u'similars': [],\n",
       "  u'tags': [],\n",
       "  u'timestamp': u'2011-09-08 01:41:45.776631',\n",
       "  u'title': u'Jericho  (Straight On Album Version)',\n",
       "  u'track_id': u'TRBBOBO128F425FDFC'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfmRDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Transform and Export Data in CSV format\n",
    "\n",
    "## Create Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the nodes that will be created\n",
    "\n",
    "|No.|Node Label|File Name| Format |\n",
    "|:--:|:--|:--|:--|\n",
    "|1|Artists|nodes_artists.csv| 'artist_id', 'artist_mbid', 'artist_7did', 'artist_name'|\n",
    "|2|Songs|nodes_songs.csv|'song_id', 'track_id', 'title', 'dance', 'dur', 'energy','loudness'|\n",
    "|3|Albums|nodes_albums.csv| 'album_name'|\n",
    "|4|Year|nodes_years.csv| 'year'|\n",
    "|5|Tags|nodes_tags.csv| 'tag'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to create CSV format from fields of dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeCSVline(line):\n",
    "    return ','.join(str(line[field]) for field in fieldsBrC.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist Nodes\n",
    "\n",
    "*CSV Format: artist_id, artist_mb_id, artist_7d_id, artist_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create artist nodes\n",
    "fields = ['artist_id', 'artist_mbid', 'artist_7did', 'artist_name']\n",
    "fieldsBrC = sc.broadcast(fields)\n",
    "\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/nodes_artists')\n",
    "# If directory already exists, delete it\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "songsRDD.map(makeCSVline).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Nodes\n",
    "\n",
    "*CSV Format: song_id, track_id, song_title, danceability, duration, energy, loudness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create song nodes\n",
    "fields = ['song_id', 'track_id', 'title', 'dance', 'dur', 'energy','loudness']\n",
    "fieldsBrC = sc.broadcast(fields)\n",
    "\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/nodes_songs')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "songsRDD.map(makeCSVline).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Album Nodes\n",
    "\n",
    "*CSV Format: album_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create album nodes\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/nodes_albums')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "songsRDD.map(lambda x: x['album']).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year Nodes\n",
    "\n",
    "*CSV Format: year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create year nodes\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/nodes_years')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "songsRDD.map(lambda x: x['year']).filter(lambda x: int(x) > 0).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Nodes\n",
    "\n",
    "*CSV Format: tag_name*\n",
    "\n",
    "The MSD data containes artist tags and  the Last.fm data containes song tags.\n",
    "\n",
    "The tags in the dataset have a large overlap. For example, the tags 'pop' and 'rock' are used to describe both artists and songs. Since the tags can be the same and convey the same information, I decided to model tags as one type of node. \n",
    "\n",
    "The tags were merged together and then the list of tags was created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tag nodes\n",
    "artistTags = songsRDD.flatMap(lambda x: x['a_terms']).distinct()\n",
    "songTags = lastfmRDD.flatMap(lambda x: x['tags']).map(lambda x: x[0]).distinct()\n",
    "\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/nodes_tags')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "allTags = songTags.union(artistTags).distinct()\n",
    "allTags.saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Number of distinct tags in each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_artistTags = artistTags.count()\n",
    "cnt_songTags = songTags.count()\n",
    "cnt_combined = allTags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist tags:\t 3,502\n",
      "Song tags:  \t33,355\n",
      "Unique tags:\t35,541\n"
     ]
    }
   ],
   "source": [
    "print 'Artist tags:\\t {:,}'.format(cnt_artistTags)\n",
    "print 'Song tags:  \\t{:,}'.format(cnt_songTags)\n",
    "print 'Unique tags:\\t{:,}'.format(cnt_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fabric saturdays venue',\n",
       " 'suicidal',\n",
       " 'protest',\n",
       " 'memphisunderground',\n",
       " 'technical progressive death metal']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistTags.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'great solo',\n",
       " u'river ssss',\n",
       " u'sacramental imagery',\n",
       " u'Yuri Gagarin',\n",
       " u'songs about birds']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songTags.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the relationships that will be created\n",
    "\n",
    "|No.|Relationship Structure|File Name| Format |\n",
    "|:--:|:--|:--|:--|\n",
    "|1|(ARTIST) - [SIMILAR_TO] -> (ARTIST)|rel_similar_artists.csv|'from_artist_id', 'to_artist_id'|\n",
    "|2|(ARTIST) - [PERFORMS] -> (SONG)|rel_performs.csv|'artist_id', 'song_id'|\n",
    "|3|(ARTIST) - [HAS_ALBUM] -> (ALBUM)|rel_artist_has_album.csv|'artist_id', 'album_name'|\n",
    "|4|(ARTIST) - [HAS_TAG] -> (TAG)|rel_artist_has_tag.csv|'artist_id', 'tag_name', 'normalized_frq', 'normalized_weight'|\n",
    "|5|(SONG) - [IN_ALBUM] -> (ALBUM)|rel_song_in_album.csv|'song_id', 'album_name'|\n",
    "|6|(SONG) - [SIMILAR_TO] -> (SONG)| rel_similar_songs.csv|'from_song_id', 'to_song_id', 'similarity_weight'|\n",
    "|7|(SONG) - [HAS_TAG] -> (TAG)| rel_song_has_tag.csv|'from_song_id', 'to_song_id', 'normalized_weight'|\n",
    "|8|(SONG) - [RELEASED_ON] -> (YEAR)| rel_song_year.csv|'song_id', 'year'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMILAR_TO relationship between artist and artist\n",
    "\n",
    "*CSV Format: from_artist_id, to_artist_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Similar Artist to Artist (directional, no properties)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_similar_artists')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "similarArtistsRDD = songsRDD.map(lambda x: (x['artist_id'],x['a_similar'])).flatMapValues(lambda x: x)\n",
    "similarArtistsRDD.distinct().map(lambda x: x[0]+\",\"+x[1]).saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORMS relationship between artist and song\n",
    "\n",
    "*CSV Format: artist_id, song_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artist Performs Song (directional, no properties)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_performs')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "songsRDD.map(lambda x: x['artist_id']+\",\"+x['song_id']).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAS_ALBUM relationship between artist and album\n",
    "\n",
    "CSV Format: artist_id, album_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artist Has Album (directional, no properties)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_artist_has_album')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "songsRDD.map(lambda x: x['artist_id']+\",\"+x['album']).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAS_TAG relationship between artist and tags\n",
    "\n",
    "*CSV Format: artist_id, tag_name, tag_frequency, tag_weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artistToTags(record):\n",
    "    '''\n",
    "    Concatenate artist with each tag\n",
    "    Normalize tag frequency and weight\n",
    "    '''\n",
    "    normalize_frq = record['a_tfrq'] / sum(record['a_tfrq'])\n",
    "    normalize_w = record['a_tw'] / sum(record['a_tw'])\n",
    "    terms = record['a_terms']\n",
    "    artist = record['artist_id']\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(terms)):\n",
    "        result.append( artist +\",\"+ terms[i] +\",\"+ str(normalize_frq[i]) +\",\"+ str(normalize_w[i]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artist Has Tags (directional, has properties frequency and weight)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_artist_has_tag')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "songsRDD.flatMap(artistToTags).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN_ALBUM relationship between song and album\n",
    "\n",
    "*CSV Format: song_id, album_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Song In Album (direction, no properties)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_song_in_album')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "songsRDD.map(lambda x: x['song_id']+\",\"+x['album']).distinct().saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMILAR_TO relationship between song and song\n",
    "\n",
    "*CSV Format: from_track_id, to_track_id, similarity_measure*\n",
    "\n",
    "Uses the track_id instead of the song_id to create the similarity relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar Song to Song (directional, with property similarity measure)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_similar_songs')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "    \n",
    "similarSongsRDD = lastfmRDD.filter(\n",
    "    lambda x: x['similars']<>[]).map(\n",
    "    lambda x: (x['track_id'],x['similars'])).flatMapValues(lambda x: x)\n",
    "similarSongsRDD.map(lambda x: x[0]+\",\"+x[1][0]+\",\"+str(x[1][1])).saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HAS_TAG relationship between song and tags\n",
    "\n",
    "*CSV Format: track_id, tag_name, tag_weight*\n",
    "\n",
    "Uses the track_id instead of song_id to identify songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def songToTags(record):\n",
    "    '''\n",
    "    Concatenate song with each tag\n",
    "    '''\n",
    "    tags = record['tags']\n",
    "    total_weight = sum(float(w[1]) for w in tags)\n",
    "    track_id = record['track_id']\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(tags)):\n",
    "        result.append( track_id +\",\"+ tags[i][0] +\",\"+ str(float(tags[i][1])/total_weight))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Song Has Tags (directional, edge with property weight)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_song_has_tag')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "lastfmRDD.flatMap(songToTags).saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELEASED_ON relationship between song and year\n",
    "\n",
    "*CSV Format: song_id, year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Song Released in Year (directional, no properties)\n",
    "outputfile = os.path.join(cdir,'MillionSongSubset/tmp/rel_song_year')\n",
    "if os.path.exists(outputfile):\n",
    "    shutil.rmtree(outputfile)\n",
    "\n",
    "songsRDD.filter(lambda x: int(x['year'])<>0).map(\n",
    "    lambda x: x['song_id']+\",\"+str(x['year'])).saveAsTextFile('file://'+outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of songs with non-zero year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4680"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsRDD.filter(lambda x: int(x['year'])<>0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Merge Spark output \n",
    "\n",
    "Spark outputs several files named 'part-000xx' which cannot be read into Neo4j. To load the data to Neo4j, I combined the Spark output into a .csv file which can be imported to Neo4j. I also added a header line for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd MillionSongSubset\n",
    "\n",
    "# Combine node files\n",
    "cat tmp/nodes_artists/part-* > graph/nodes_artists.csv\n",
    "cat tmp/nodes_songs/part-*   > graph/nodes_songs.csv\n",
    "cat tmp/nodes_albums/part-*  > graph/nodes_albums.csv\n",
    "cat tmp/nodes_years/part-*   > graph/nodes_years.csv\n",
    "cat tmp/nodes_tags/part-*    > graph/nodes_tags.csv\n",
    "\n",
    "# Add headers to nodes\n",
    "sed -i '1iartist_id,artist_mbid,artist_7did,artist_name' graph/nodes_artists.csv\n",
    "sed -i '1isong_id,track_id,song_name,danceability,duration,energy,loudness' graph/nodes_songs.csv\n",
    "sed -i '1ialbum_name' graph/nodes_albums.csv\n",
    "sed -i '1iyear' graph/nodes_years.csv\n",
    "sed -i '1itag_name' graph/nodes_tags.csv\n",
    "\n",
    "\n",
    "# Combine relationship files\n",
    "cat tmp/rel_artist_has_album/part-* > graph/rel_artist_has_album.csv\n",
    "cat tmp/rel_artist_has_tag/part-*   > graph/rel_artist_has_tag.csv\n",
    "cat tmp/rel_performs/part-*         > graph/rel_performs.csv\n",
    "cat tmp/rel_similar_artists/part-*  > graph/rel_similar_artists.csv\n",
    "cat tmp/rel_similar_songs/part-*    > graph/rel_similar_songs.csv\n",
    "cat tmp/rel_song_has_tag/part-*     > graph/rel_song_has_tag.csv\n",
    "cat tmp/rel_song_in_album/part-*    > graph/rel_song_in_album.csv\n",
    "cat tmp/rel_song_year/part-*        > graph/rel_song_year.csv\n",
    "\n",
    "# Add headers to relationships\n",
    "sed -i '1iartist_id,album_name' graph/rel_artist_has_album.csv\n",
    "sed -i '1iartist_id,tag_name,tag_frq,tag_w' graph/rel_artist_has_tag.csv\n",
    "sed -i '1iartist_id,song_id' graph/rel_performs.csv\n",
    "sed -i '1ifrom_artist,to_artist' graph/rel_similar_artists.csv\n",
    "sed -i '1ifrom_track,to_track,sim_measure' graph/rel_similar_songs.csv\n",
    "sed -i '1itrack_id,tag_name,tag_w' graph/rel_song_has_tag.csv\n",
    "sed -i '1isong_id,album_name' graph/rel_song_in_album.csv\n",
    "sed -i '1isong_id,year' graph/rel_song_year.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load CSV files to Neo4j\n",
    "\n",
    "Loading the data into Neo4j was done in the notebook [Step 3 - Load Subset to Neo.ipynb](./Step 3 - Load Subset to Neo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Scripts\n",
    "\n",
    "The notebook [Step 4 - Process Entire Dataset.ipynb](./Step 4 - Process Entire Dataset.ipynb) has the final scripts developed to process the entire Million Song Dataset and a description of how to run those scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
