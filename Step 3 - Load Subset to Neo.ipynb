{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the 10,000 Song Subset to Neo4j\n",
    "\n",
    "*Andrea Soto*  \n",
    "*MIDS W205 Final Project*  \n",
    "*Project Name: Graph Model of the Million Song Dataset*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook is a continuation of the notebook [Step 2 - Process Subset.ipynb](./Step 2 - Process Subset.ipynb) were the CSV files containing the graph nodes and relationships were created. **The goal of this notebook is to load the subset dataset with 10,000 songs into Neo4j.** The code developed was then compiled in scripts that were used to process the full data.\n",
    "\n",
    "The tables below summarize the files that contain the graph data. These files are located in the directory **MillionSongSubset/graph**.\n",
    "\n",
    "**Nodes**\n",
    "\n",
    "|No.|Node Label|File Name| Format |\n",
    "|:--:|:--|:--|:--|\n",
    "|1|Artists|nodes_artists.csv| 'artist_id', 'artist_mbid', 'artist_7did', 'artist_name'|\n",
    "|2|Songs|nodes_songs.csv|'song_id', 'track_id', 'title', 'dance', 'dur', 'energy','loudness'|\n",
    "|3|Albums|nodes_albums.csv| 'album_name'|\n",
    "|4|Year|nodes_years.csv| 'year'|\n",
    "|5|Tags|nodes_tags.csv| 'tag'|\n",
    "\n",
    "**Relationships**\n",
    "\n",
    "|No.|Relationship Structure|File Name| Format |\n",
    "|:--:|:--|:--|:--|\n",
    "|1|(ARTIST) - [SIMILAR_TO] -> (ARTIST)|rel_similar_artists.csv|'from_artist_id', 'to_artist_id'|\n",
    "|2|(ARTIST) - [PERFORMS] -> (SONG)|rel_performs.csv|'artist_id', 'song_id'|\n",
    "|3|(ARTIST) - [HAS_ALBUM] -> (ALBUM)|rel_artist_has_album.csv|'artist_id', 'album_name'|\n",
    "|4|(ARTIST) - [HAS_TAG] -> (TAG)|rel_artist_has_tag.csv|'artist_id', 'tag_name', 'normalized_frq', 'normalized_weight'|\n",
    "|5|(SONG) - [IN_ALBUM] -> (ALBUM)|rel_song_in_album.csv|'song_id', 'album_name'|\n",
    "|6|(SONG) - [SIMILAR_TO] -> (SONG)| rel_similar_songs.csv|'from_song_id', 'to_song_id', 'similarity_weight'|\n",
    "|7|(SONG) - [HAS_TAG] -> (TAG)| rel_song_has_tag.csv|'from_song_id', 'to_song_id', 'normalized_weight'|\n",
    "|8|(SONG) - [RELEASED_ON] -> (YEAR)| rel_song_year.csv|'song_id', 'year'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from py2neo import authenticate\n",
    "import os\n",
    "\n",
    "path = 'file:' + os.getcwd() + '/MillionSongSubset/graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that requiered enviroment names exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/graph/neo4j/bin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['NEO4J_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ec2-54-91-193-97.compute-1.amazonaws.com'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['INSTANCE_PDNS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Neo4j Server\n",
    "\n",
    "Assumes the environment variable NEO4J_HOME exists and points to [installation_path]/neo4j/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Max 1024 open files allowed, minimum of 40 000 recommended. See the Neo4j manual.\n",
      "Starting Neo4j Server...WARNING: not changing user\n",
      "process [27766]... waiting for server to be ready....... OK.\n",
      "http://localhost:7474/ is ready.\n"
     ]
    }
   ],
   "source": [
    "!$NEO4J_HOME/neo4j start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdns = os.environ['INSTANCE_PDNS']\n",
    "\n",
    "# Authenticate\n",
    "authenticate(pdns+\":7474\", \"neo4j\", \"redpill\")\n",
    "\n",
    "# connect to authenticated graph database\n",
    "graph = Graph(\"http://\"+pdns+\":7474/db/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from py2neo.packages.httpstream import http\n",
    "http.socket_timeout = 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique constraints and index for 'track_id' property of SONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of constraints to create (if not in place already)\n",
    "unique_constraints = [('ARTIST', 'id'),('SONG','id'),('ALBUM','name'),('TAG','tag'),('YEAR','year')]\n",
    "\n",
    "for label,prop in unique_constraints:\n",
    "    try:\n",
    "        # Create constraint\n",
    "        graph.schema.create_uniqueness_constraint(label, prop)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Create index\n",
    "try:\n",
    "    graph.schema.create_index('SONG','trackid')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 0 ns, total: 3 ms\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Artists\n",
    "csv_path = path + 'nodes_artists.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MERGE (a:ARTIST {id:line.artist_id}) '\n",
    "st += 'ON CREATE SET a.idmb=line.artist_mbid, a.id7d=line.artist_7did, a.name=lower(line.artist_name);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 0 ns, total: 2 ms\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Songs\n",
    "csv_path = path + 'nodes_songs.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MERGE (s:SONG {id:line.song_id}) '\n",
    "st += 'ON CREATE SET s.trackid=line.track_id, s.title=lower(line.song_name),'\n",
    "st += 's.danceability=TOFLOAT(line.danceability),s.duration = TOFLOAT(line.duration),'\n",
    "st += 's.energy= TOFLOAT(line.energy), s.loudness = TOFLOAT(line.loudness);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 0 ns, total: 2 ms\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Albums\n",
    "csv_path = path + 'nodes_albums.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MERGE (a:ALBUM {name: lower(line.album_name)});'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 0 ns, total: 2 ms\n",
      "Wall time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Year\n",
    "csv_path = path + 'nodes_years.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MERGE (y:YEAR {year: TOINT(line.year)});'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 1 ms, total: 3 ms\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tags\n",
    "csv_path = path + 'nodes_tags.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MERGE (:TAG {tag: lower(line.tag_name)});'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Artist - SIMILAR_TO -> Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 12.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# (ARTIST)-[SIMILAR_TO]-> (ARTIST)\n",
    "csv_path = path + 'rel_similar_artists.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (from:ARTIST {id:line.from_artist}) '\n",
    "st += 'MATCH (to:ARTIST {id:line.to_artist}) '\n",
    "st += 'MERGE (from)-[:SIMILAR_TO]->(to)'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Artist - PERFORMS -> Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 999 µs, total: 4 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (ARTIST)-[PERFORMS]-> (SONG)\n",
    "csv_path = path + 'rel_performs.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (a:ARTIST {id:line.artist_id}) '\n",
    "st += 'MATCH (s:SONG {id:line.song_id}) '\n",
    "st += 'MERGE (a)-[:PERFORMS]->(s)'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Artist - HAS_ALBUM -> Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 1 ms, total: 3 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (ARTIST)-[HAS_ALBUM]-> (ALBUM)\n",
    "csv_path = path + 'rel_artist_has_album.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (a:ARTIST {id:line.artist_id}) '\n",
    "st += 'MATCH (m:ALBUM {name:lower(line.album_name)}) '\n",
    "st += 'MERGE (a)-[:HAS_ALBUM]->(m);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Artist - HAS_TAG -> Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (ARTIST)-[HAS_TAG]-> (TAG)\n",
    "csv_path = path + 'rel_artist_has_tag.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (a:ARTIST {id:line.artist_id}) '\n",
    "st += 'MATCH (t:TAG {tag:lower(line.tag_name)}) '\n",
    "st += 'MERGE (a)-[r:HAS_TAG]->(t)'\n",
    "st += 'ON CREATE SET r.frq=TOFLOAT(line.tag_frq), r.weight=TOFLOAT(line.tag_w);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Song - IN_ALBUM -> Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 1 ms, total: 3 ms\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (SONG)-[IN_ALBUM]-> (ALBUM)\n",
    "csv_path = path + 'rel_song_in_album.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (s:SONG {id:line.song_id}) '\n",
    "st += 'MATCH (a:ALBUM {name:lower(line.album_name)}) '\n",
    "st += 'MERGE (s)-[:IN_ALBUM]->(a);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Song - SIMILAR_TO -> Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/data/asoto/projectW205/MillionSongSubset/graph/rel_similar_songs.csv'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path + 'rel_similar_songs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/asoto/projectW205\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_track,to_track,sim_measure\r\n",
      "TRBBOPX12903D106F7,TRNTHZA12903D106FA,1\r\n",
      "TRBBOPX12903D106F7,TRWXSDH12903D106F2,0.97073\r\n",
      "TRBBOPX12903D106F7,TREOIQG12903CC9DE1,0.0727542\r\n",
      "TRBBOPX12903D106F7,TRYJWDG128F930AA09,0.0714807\r\n",
      "TRBBOPX12903D106F7,TROQSRY128F930E0D5,0.0546577\r\n",
      "TRBBOPX12903D106F7,TRPNFCQ128F930AA02,0.0542935\r\n",
      "TRBBOPX12903D106F7,TRDLDXL12903CFFF83,0.0537399\r\n",
      "TRBBOPX12903D106F7,TRYNNVL12903CFFF78,0.0536009\r\n",
      "TRBBOPX12903D106F7,TRBLAPG128F4244368,0.0534808\r\n"
     ]
    }
   ],
   "source": [
    "!head MillionSongSubset/graph/rel_similar_songs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# (SONG)-[SIMILAR_TO]-> (SONG)\n",
    "csv_path = path + 'rel_similar_songs.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (from:SONG {trackid:line.from_track}) '\n",
    "st += 'MATCH (to:SONG {trackid:line.to_track}) '\n",
    "st += 'MERGE (from)-[r:SIMILAR_TO]->(to)'\n",
    "st += 'ON CREATE SET r.weight=TOFLOAT(line.sim_measure);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Song - HAS_TAG -> Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ms, sys: 4 ms, total: 6 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (SONG)-[HAS_TAG]-> (TAG)\n",
    "csv_path = path + 'rel_song_has_tag.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (s:SONG {trackid:line.track_id}) '\n",
    "st += 'MATCH (t:TAG {tag:lower(line.tag_name)}) '\n",
    "st += 'MERGE (s)-[r:HAS_TAG]->(t)'\n",
    "st += 'ON CREATE SET r.weight=TOFLOAT(line.tag_w);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Song - RELEASED_ON -> Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 ms, sys: 1 ms, total: 2 ms\n",
      "Wall time: 942 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (SONG)-[RELEASED_ON]-> (YEAR)\n",
    "csv_path = path + 'rel_song_year.csv'\n",
    "\n",
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'USING PERIODIC COMMIT 1000 '\n",
    "st += 'LOAD CSV WITH HEADERS FROM \"' + csv_path + '\" AS line '\n",
    "st += 'MATCH (s:SONG {id:line.song_id}) '\n",
    "st += 'MATCH (y:YEAR {year:TOINT(line.year)}) '\n",
    "st += 'MERGE (s)-[:RELEASED_ON]->(y);'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Quick queries to confirm data was loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | LABELS(n)   | count(n)\n",
       "---+-------------+----------\n",
       " 1 | [u'ALBUM']  |     7823\n",
       " 2 | [u'TAG']    |    35112\n",
       " 3 | [u'SONG']   |    10000\n",
       " 4 | [u'YEAR']   |       69\n",
       " 5 | [u'ARTIST'] |     3888\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'MATCH n RETURN DISTINCT LABELS(n), count(n)'\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | This   | To          | That   | count(r)\n",
       "---+--------+-------------+--------+----------\n",
       " 1 | SONG   | IN_ALBUM    | ALBUM  |    10000\n",
       " 2 | SONG   | SIMILAR_TO  | SONG   |     9215\n",
       " 3 | SONG   | RELEASED_ON | YEAR   |     4680\n",
       " 4 | ARTIST | HAS_ALBUM   | ALBUM  |     8061\n",
       " 5 | ARTIST | HAS_TAG     | TAG    |    96825\n",
       " 6 | SONG   | HAS_TAG     | TAG    |    99296\n",
       " 7 | ARTIST | PERFORMS    | SONG   |    10000\n",
       " 8 | ARTIST | SIMILAR_TO  | ARTIST |    42970\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = graph.cypher.begin()\n",
    "\n",
    "st = 'MATCH (a)-[r]->(b) '\n",
    "st += 'WHERE labels(a) <> [] AND labels(b) <> [] '\n",
    "st += 'RETURN DISTINCT head(labels(a)) AS This, type(r) as To, head(labels(b)) AS That, count(r) '\n",
    "st += 'LIMIT 10 '\n",
    "\n",
    "tx.append(st)\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MATCH p=(:ARTIST)-->(s:SONG)-->(:SONG)<--(:ARTIST)\n",
    "WHERE s.title = \"don't stop the music\"\n",
    "RETURN p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sample Query](./images/Query_DontStopTheMusic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Scripts\n",
    "\n",
    "The notebook [Step 4 - Process Entire Dataset.ipynb](./Step 4 - Process Entire Dataset.ipynb) has the final scripts developed to process the entire Million Song Dataset and a description of how to run the scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
