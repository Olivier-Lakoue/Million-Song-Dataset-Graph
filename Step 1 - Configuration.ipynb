{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "*Andrea Soto*  \n",
    "*MIDS W205 Final Project*  \n",
    "*Project Name: Graph Model of the Million Song Dataset*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Requirements:\n",
    "\n",
    "- W205 AMI with Hadoop and Spark. A **c3.8xlarge** instance with 32 CPUs was initialized to processes the entire MSD. This instance took approximately 14 hours to extract all the data and create the CSV files for Neo4j.\n",
    "- AWS CLI installed and configured:\n",
    "\n",
    "> **`$ pip install awscli`**  \n",
    "> **`$ aws configure`**  \n",
    "> AWS Access Key ID [None]: *enter_access_key*  \n",
    "> AWS Secret Access Key [None]: *enter_secret_access_key*  \n",
    "> Default region name [None]: *us-east-1*  \n",
    "> Default output format [None]: *json*  \n",
    "\n",
    "## Additional Requirements\n",
    "\n",
    "Additional requierements will be installed with the configurations scripts in this notebook. These scritps are runned from within the EC2 instance and assume that the project's github repository has been cloned:\n",
    "\n",
    "> `git clone git@github.com:andrea-soto/W205_FinalProject.git`\n",
    "\n",
    "The configuration scripts described in this notebook are located under the folder **'config'**\n",
    "\n",
    "## Environment Names\n",
    "\n",
    "The following enviroment names should exist after the setup:\n",
    "\n",
    "- **NEO4J_HOME**=\"/graph/neo4j/bin\"\n",
    "- **INSTANCE_PDNS**=\"c2-54-155-21-219.compute-1.amazonaws.com\"\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install jq and ec2-metadata (as root user)\n",
    "\n",
    "**Script Path and Name:** config/install-jq-ec2meta.sh  \n",
    "**Script Description:** Install [jq](https://stedolan.github.io/jq/) to parse json in the command line and [ec3-metadata](https://aws.amazon.com/code/1825) to query information about current instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/install-jq-ec2meta.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/install-jq-ec2meta.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# Install jq to parse JSON in shell\n",
    "sudo yum install jq\n",
    "\n",
    "# Install EC2 Instance Metadata Query Tool\n",
    "wget http://s3.amazonaws.com/ec2metadata/ec2-metadata\n",
    "chmod a+x ec2-metadata\n",
    "mv ec2-metadata /usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x config/install-jq-ec2meta.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create and Attach EBS volumes to current instance (as root)\n",
    "\n",
    "Attache 2 volumes to this instance:\n",
    "\n",
    "- **Graph Volume:** 200GB volume created to store the graph and interim files. This volume was mounted under the folder '/graph'\n",
    "- **MSD Volume:** 500GB volume created from the AWS snapshot *snap-5178cf30* with the entire Million Song Dataset (MSD). This volume was mounted under the folder 'msong_dataset'. For details about the snapshot see [AWS Datasets](https://aws.amazon.com/datasets/million-song-dataset/)\n",
    "\n",
    "**Script Path and Name:** config/create_volumes.sh  \n",
    "**Script Description:** Create the volumes described above, attache them to instance, and mount them for use\n",
    "\n",
    "The environment names used in the script are set using ec3-metadata and should look something like this:\n",
    "- INSTANCE_ID=i-ds107669\n",
    "- INSTANCE_PDNS=ec2-54-155-21-219.compute-1.amazonaws.com\n",
    "- INSTANCE_ZONE=us-east-1c\n",
    "- GRAPH_VOL_ID=vol-7e18339d\n",
    "- MSD_VOL_ID=vol-7e18339d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/create_volumes.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/create_volumes.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# =============================================\n",
    "# RUN SCRIPT AS ROOT USER\n",
    "# Attaches 2 volumes to this instance: a Graph Volume of 200 GB mounted to /graph\n",
    "# and a MSD Volume 280GB from snap-5178cf30 with the entire dataset mounted to /msong_dataset\n",
    "\n",
    "cd ~\n",
    "\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Save instance info in environment variables\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "# Get instance id\n",
    "INSTANCE_ID=$(ec2-metadata -i | cut -d:  -f2| cut -d' ' -f2)\n",
    "export INSTANCE_ID\n",
    "# Get instance public hostname\n",
    "INSTANCE_PDNS=$(ec2-metadata -p | cut -d:  -f2| cut -d' ' -f2)\n",
    "export INSTANCE_PDNS\n",
    "# Get instance availability zone\n",
    "INSTANCE_ZONE=$(ec2-metadata -z | cut -d:  -f2| cut -d' ' -f2)\n",
    "export INSTANCE_ZONE\n",
    "\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Create Volumes\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "mkdir -p aws-info\n",
    " \n",
    "### Create volume to store graph\n",
    "echo LOG: Creating graph volume...\n",
    "aws ec2 create-volume --size 200 --availability-zone $INSTANCE_ZONE --volume-type gp2 > aws-info/graph-volume.json\n",
    "wait\n",
    "GRAPH_VOL_ID=$(jq '.VolumeId' aws-info/graph-volume.json)\n",
    "GRAPH_VOL_ID=\"${GRAPH_VOL_ID%\\\"}\"\n",
    "GRAPH_VOL_ID=\"${GRAPH_VOL_ID#\\\"}\"\n",
    "export GRAPH_VOL_ID\n",
    "\n",
    "### Create volume from AWS snapshot of Million Song Dataset (full dataset)\n",
    "echo LOG: Copying Million Song Dataset volume...\n",
    "aws ec2 create-volume --availability-zone $INSTANCE_ZONE \\\n",
    "--snapshot-id snap-5178cf30 --volume-type gp2 > aws-info/msd-volume.json\n",
    "wait\n",
    "MSD_VOL_ID=$(jq '.VolumeId' aws-info/msd-volume.json)\n",
    "MSD_VOL_ID=\"${MSD_VOL_ID%\\\"}\"\n",
    "MSD_VOL_ID=\"${MSD_VOL_ID#\\\"}\"\n",
    "export MSD_VOL_ID\n",
    "\n",
    "echo LOG: Wait for volumes to become available...\n",
    "\n",
    "sleep 30\n",
    "\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Attache volumes to this instance\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    \n",
    "echo LOG: Attaching graph volumne...\n",
    "aws ec2 attach-volume --volume-id $GRAPH_VOL_ID --instance-id $INSTANCE_ID --device /dev/xvdj\n",
    "\n",
    "echo LOG: Attaching Million Song Dataset volume...\n",
    "aws ec2 attach-volume --volume-id $MSD_VOL_ID --instance-id $INSTANCE_ID --device /dev/xvdk\n",
    "\n",
    "echo LOG: Wait for volumes to be attached...\n",
    "    \n",
    "sleep 30 \n",
    "\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Mount volumes to instance\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "mkdir -p /graph\n",
    "sudo mkfs -t ext4 /dev/xvdh\n",
    "sudo mount -t ext4 /dev/xvdj /graph\n",
    "chmod g+rwx -R /graph/\n",
    "\n",
    "mkdir -p /msong_dataset\n",
    "sudo mount /dev/xvdk /msong_dataset\n",
    "\n",
    "echo LOG: Check volumes were created and mounted...\n",
    "lsblk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x config/create_volumes.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Anaconda and h5py (as user)\n",
    "\n",
    "**Script Path and Name:** config/install_anaconda.sh  \n",
    "**Script Description:** Install anaconda and then h5py under the directory **'/graph'** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!su - asoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/install_anaconda.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/install_anaconda.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "cd /graph\n",
    "wget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.1-Linux-x86_64.sh\n",
    "bash Anaconda2-2.4.1-Linux-x86_64.sh\n",
    "conda install h5py    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Neo4j in /graph directory (as user)\n",
    "\n",
    "**Script Path and Name:** config/install_neo4j.sh  \n",
    "**Script Description:** Install neo4j under the directory **'/graph'** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/install_neo4j.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/install_neo4j.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# === Install Neo4j in /graph directory ===\n",
    "\n",
    "echo LOG: Installing Neo4j in /graph ...\n",
    "cd ~\n",
    "cd /graph\n",
    "wget http://neo4j.com/artifact.php?name=neo4j-community-2.3.1-unix.tar.gz\n",
    "tar -xf artifact.php\\?name\\=neo4j-community-2.3.1-unix.tar.gz\n",
    "rm artifact.php\\?name\\=neo4j-community-2.3.1-unix.tar.gz\n",
    "mv neo4j-community-2.3.1/ neo4j/\n",
    "NEO4J_HOME=\"/graph/neo4j/bin\"\n",
    "export NEO4J_HOME\n",
    "\n",
    "echo 'org.neo4j.server.webserver.address = 0.0.0.0' >> /graph/neo4j/conf/neo4j-server.properties\n",
    "\n",
    "echo LOG: Installing py2neo and updating password of user 'neo4j' ...\n",
    "pip install py2neo\n",
    "neoauth neo4j neo4j redpill\n",
    "\n",
    "echo LOG: Password set to 'redpill'...\n",
    "echo to change pasword run: neoauth neo4j redpill <new-password>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download last.fm dataset and mismatch data (as user)\n",
    "\n",
    "**Script Path and Name:** config/download_lastfm.sh  \n",
    "**Script Description:** Download Last.fm dataset and store it under the directory **'/graph/lastfm'**. Download mismatch data and store it under the directory **'/graph/import'**\n",
    "\n",
    "> The MSD team found some matching errors between tracks and songs in the data. They created a list of (song id, tack id) pairs that are not trusted and they suggest removing this pairs from the data. These missmatches were removed from the data as part of the transformation process and they were not included in the original Last.fm dataset.\n",
    "\n",
    "> For more details see:\n",
    "- http://labrosa.ee.columbia.edu/millionsong/blog/12-1-2-matching-errors-taste-profile-and-msd\n",
    "- http://labrosa.ee.columbia.edu/millionsong/blog/12-2-12-fixing-matching-errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/download_lastfm.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/download_lastfm.sh\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "mkdir /graph/import\n",
    "mkdir /graph/lastfm\n",
    "\n",
    "cd /graph/lastfm\n",
    "mkdir data\n",
    "\n",
    "wget http://labrosa.ee.columbia.edu/millionsong/sites/default/files/lastfm/lastfm_train.zip\n",
    "wget http://labrosa.ee.columbia.edu/millionsong/sites/default/files/lastfm/lastfm_test.zip\n",
    "\n",
    "unzip -q lastfm_train.zip\n",
    "mv lastfm_train/* data/\n",
    "\n",
    "unzip -q lastfm_test.zip\n",
    "rsync -av lastfm_test/ data/\n",
    "\n",
    "rm lastfm_train.zip\n",
    "rm lastfm_test.zip\n",
    "rm -r lastfm_train/\n",
    "rm -r lastfm_test/\n",
    "\n",
    "cd /graph/import\n",
    "wget http://labrosa.ee.columbia.edu/millionsong/sites/default/files/tasteprofile/sid_mismatches.txt\n",
    "    \n",
    "cd /graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#echo 'export INSTANCE_ID='$INSTANCE_ID >> ~/.bashrc\n",
    "#echo 'export INSTANCE_PDNS='$INSTANCE_PDNS >> ~/.bashrc\n",
    "#echo 'export INSTANCE_ZONE='$INSTANCE_ZONE >> ~/.bashrc\n",
    "#source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Unmount volumes from instance\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "umount /graph\n",
    "umount /msong_dataset\n",
    "\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "# Detaching volumes from this instance\n",
    "# ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    \n",
    "echo LOG: Detaching graph volumne...\n",
    "aws ec2 detach-volume --volume-id $GRAPH_VOL_ID --instance-id $INSTANCE_ID\n",
    "\n",
    "echo LOG: Detaching Million Song Dataset volume...\n",
    "aws ec2 detach-volume --volume-id $MSD_VOL_ID --instance-id $INSTANCE_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
